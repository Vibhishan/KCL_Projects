{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas package is an extremely powerful library for manipulating tabulated data. Similar in some ways to EXCELL, pandas provides functionality for reading data from spreadsheets (in a range of formats including excell, csv and pickle files); presenting them as a Dataframe object. Through this it becomes possible to search, filter and manipulate the data entries. In this notebook we will go through some of the basic functionality of Pandas, sufficient for reading in data, selecting columns and filtering by different search categories. \n",
    "\n",
    "We start by importing Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is capable of working with data from a range of statistical software packages (EXCELL, SQL, STATA, SAS). In this course we will focus simply on reading from .csv and pickle files e.g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data=pd.read_pickle('40subjdata.pk1') #reading from a pickle file\n",
    "dHCP_volume_data=pd.read_csv('dHCP_volume_data.csv',header=None) # reading from a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open 'dHCP_volume_data.csv' using excell. You will note it has no column names. Thus in order to load all data correctly (and avoid the first row of data being read in as column headers) it is necessary to supplement the call to ```read_csv``` with an additional argument ```header=None```. Other potentially important read arguments include ```sep``` or ```delimeter``` which define the delimeter used to separate the columns in the saved spreadsheet. For more information see (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). \n",
    "\n",
    "To avoid this confusion over csv formatting it is generally better to save and then reload Dataframes as pickle files (see https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_pickle.html.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing and Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides several functions for viewing subsections of the DataFrame and estimating summary statistics across columns. For example it is possible to read the first (or last) few rows of the data using the ```head``` and ```tail``` functions respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_data.head(3))\n",
    "print(student_data.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1:__ Print first 10 and last 7 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition several functions are provided to summarise statistics across columns e.g:\n",
    "\n",
    "-  df.mean() Returns the mean of all columns\n",
    "-  df.max()  Returns the highest value in each column\n",
    "-  df.min() Returns the lowest value in each column\n",
    "-  df.median() Returns the median of each column\n",
    "-  df.std() Returns the standard deviation of each column\n",
    "-  df.corr() Returns the correlation between columns in a data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes can be created from Dictionaries, Lists or Numpy arrays. Below is an example of creating a new dataframe from a 4 column array, within given column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array of random numbers with four columns\n",
    "random_array=np.random.randint(0,100,size=(10,4))\n",
    "\n",
    "# creating a new data frame object from the random array and providing column  labels\n",
    "df=pd.DataFrame(random_array,index=['a','b','c','d','e','f','g' ,'h','i','j'],columns=['A','B','C','D'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2__: Create an array of 100 rows and 2 columns and populate it with normally distributed random values (_Hint_: `randn`). Create a data frame object from this array (do not provide index labels this time, only column labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2\n",
    "gaussian_array = None\n",
    "df2 = None\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New columns can straightforwardly be added in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['E']=df['A']+df['B']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowing you to create new columns of data from existing columns, as you would in EXCELL.\n",
    "\n",
    "__Task 3__: Create a new column called 'F' containing: $mean(A) + 5*B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns and rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to select a single column from a DataFrame using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']\n",
    "\n",
    "print('Column object type:', type(df['A']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see a DataFrame column is represented by a separated datatype: a Series. Essentially a Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.). The axis labels are collectively called index. Rows can be selected as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a range of columns and rows (using the column names and row indices) use the ```.loc``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a range or rows and columns by name\n",
    "df.loc['a':'d','A':'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be used to obtain a single scalar value, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a scalar value\n",
    "print('Selecting a single value: {}, given type: {}'.format(df.loc['b','A'],type(df.loc['b','A'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to slice by column and row number use ```iloc```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a range or rows and columns by number\n",
    "df.iloc[0:4,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 4:__ From `student_data` select\n",
    "1. Rows 2 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Column 'height'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rows 0 and 1 and columns 0 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Rows 0 to 2 and columns 'distance' to 'height'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be filtered using conditional statements such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['A'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This selects all rows for which the values in the column 'A' are greater than 50. To further reduce this data to the values in column 'C':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['C'][df['A'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 5:__ Select the column 'height' for the female students only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally it can be useful to iterate through all the rows in the DataFrame (for example if it stores paths to files that need to be processed). This can be achieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index,row['A'],row['E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ```row``` is a Series containing the content of each indexed row. The values from different columns in this row can therefore be indexed as `row['A'], row['B']` ... etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you will want to merge two DataFrames that share information. For example, creating a new DataFrame that shares Columns 'A' and 'B' with ```df```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array of random numbers with four columns\n",
    "random_array=np.random.randint(0,100,size=(10,3))\n",
    "\n",
    "# creating a new data frame object from the random array and providing column  labels\n",
    "df_new=pd.DataFrame(random_array,index=['a','b','c','d','e','f','g' ,'h','i','j'],columns=['F','G','H'])\n",
    "df_new['A']=df['A']\n",
    "df_new['B']=df['B']\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the two DataFrames can be merged on these columns using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df.merge(df_new, on=['A','B'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as seen prevously for the MatplotLib tutorial. It is possible to directly plot the columns of the DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(student_data['height'],student_data['distance'])\n",
    "plt.xlabel('height')\n",
    "plt.ylabel('Distance Travelled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 6:__ Plot a histogram of heights of the female students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations & Extended Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Pandas in your research you should consider citing\n",
    "\n",
    "Wes McKinney. Data Structures for Statistical Computing in Python, Proceedings of the 9th Python in Science Conference, 51-56 (2010) (publisher link)\n",
    "\n",
    "For more comprehensive tutorials on using Pandas see:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/tutorials.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
